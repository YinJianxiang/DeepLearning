{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d81d38d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out = [0.9482299 0.        1.1610144 2.747859  0.        1.36677  ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)\n",
    "\n",
    "import resnets_utils \n",
    "\n",
    "def identity_block(X, f, filters, stage, block):\n",
    "    \"\"\"\n",
    "    功能：\n",
    "    实现恒等块\n",
    "    参数：\n",
    "    X:输入数据,维度(m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f:第二部分卷积层的维度\n",
    "    filters:每部分卷积层的过滤器个数\n",
    "    stage:命名参数，层数\n",
    "    block:命名参数，层的名字\n",
    "    返回值：\n",
    "    X_out:恒等快输出，维度(n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "\n",
    "    conv_name_base = \"res\" + str(stage) + block + \"_branch\"\n",
    "    bn_name_base   = \"bn\"  + str(stage) + block + \"_branch\"\n",
    "    \n",
    "\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    X_shortcut = X\n",
    "    \n",
    "    #第一部分\n",
    "    X = Conv2D(filters=F1, \n",
    "               kernel_size=(1,1), \n",
    "               strides=(1,1),\n",
    "               padding=\"valid\",\n",
    "               name=conv_name_base+\"2a\", \n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3,name=bn_name_base+\"2a\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    #第二部分\n",
    "    X = Conv2D(filters=F2, \n",
    "               kernel_size=(f,f),\n",
    "               strides=(1,1), \n",
    "               padding=\"same\",\n",
    "               name=conv_name_base+\"2b\", \n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3,name=bn_name_base+\"2b\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    \n",
    "    #第三部分\n",
    "    X = Conv2D(filters=F3,\n",
    "               kernel_size=(1,1), \n",
    "               strides=(1,1),\n",
    "               padding=\"valid\",\n",
    "               name=conv_name_base+\"2c\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3,name=bn_name_base+\"2c\")(X)\n",
    "\n",
    "    X = Add()([X,X_shortcut])\n",
    "    X_output = Activation(\"relu\")(X)\n",
    "\n",
    "    return X_output\n",
    "\n",
    "\n",
    "#test 恒等快\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as test:\n",
    "    np.random.seed(1)\n",
    "    A_prev = tf.placeholder(\"float\",[3,4,4,6])\n",
    "    X = np.random.randn(3,4,4,6)\n",
    "    A = identity_block(A_prev,f=2,filters=[2,4,6],stage=1,block=\"a\")\n",
    "    \n",
    "    test.run(tf.global_variables_initializer())\n",
    "    out = test.run([A],feed_dict={A_prev:X,K.learning_phase():0})\n",
    "    print(\"out = \" + str(out[0][1][1][0]))\n",
    "    \n",
    "    test.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe7adfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out = [0.09018461 1.2348977  0.46822017 0.0367176  0.         0.655166  ]\n"
     ]
    }
   ],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
    "    \"\"\"\n",
    "    功能：\n",
    "    实现跳跃三层的恒等快\n",
    "    参数：\n",
    "    X:输入数据,维度(m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f:第二部分卷积层的维度\n",
    "    filters:每部分卷积层的过滤器个数\n",
    "    stage:命名参数，层数\n",
    "    block:命名参数，层的名字\n",
    "    s:第一部分、第三部分、X_shortcut的stride\n",
    "    返回值：\n",
    "    X_out:恒等快输出，维度(n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    conv_name_base = \"res\" + str(stage) + block + \"_branch\"\n",
    "    bn_name_base = \"bn\" + str(stage) + block + \"_branch\"\n",
    "    \n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    X_shortcut = X\n",
    "    \n",
    "    #第一部分\n",
    "    X = Conv2D(filters = F1, \n",
    "               kernel_size=(1,1),\n",
    "               strides=(s,s),\n",
    "               padding=\"valid\",\n",
    "               name=conv_name_base+\"2a\",\n",
    "               kernel_initializer=glorot_uniform(seed=0)\n",
    "              )(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base+\"2a\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    #第二部分\n",
    "    X = Conv2D(filters = F2, \n",
    "               kernel_size=(f,f),\n",
    "               strides=(1,1),\n",
    "               padding=\"same\",\n",
    "               name=conv_name_base+\"2b\",\n",
    "               kernel_initializer=glorot_uniform(seed=0)\n",
    "              )(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base+\"2b\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    #第三部分\n",
    "    X = Conv2D(filters = F3, \n",
    "               kernel_size=(1,1),\n",
    "               strides=(1,1),\n",
    "               padding=\"valid\",\n",
    "               name=conv_name_base+\"2c\",\n",
    "               kernel_initializer=glorot_uniform(seed=0)\n",
    "              )(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base+\"2c\")(X)\n",
    "    \n",
    "    #shortcut\n",
    "    X_shortcut = Conv2D(filters = F3, \n",
    "               kernel_size=(1,1),\n",
    "               strides=(s,s),\n",
    "               padding=\"valid\",\n",
    "               name=conv_name_base+\"1\",\n",
    "               kernel_initializer=glorot_uniform(seed=0)\n",
    "              )(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base+\"1\")(X_shortcut)\n",
    "    \n",
    "    #求和\n",
    "    X = Add()([X, X_shortcut])\n",
    "    #激活\n",
    "    X_output = Activation(\"relu\")(X)\n",
    "    \n",
    "    return X_output    \n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as test:\n",
    "    np.random.seed(1)\n",
    "    A_prev = tf.placeholder(\"float\",[3,4,4,6])\n",
    "    X = np.random.randn(3,4,4,6)\n",
    "    \n",
    "    A = convolutional_block(A_prev,f=2,filters=[2,4,6],stage=1,block=\"a\")\n",
    "    test.run(tf.global_variables_initializer())\n",
    "    \n",
    "    out = test.run([A],feed_dict={A_prev:X,K.learning_phase():0})\n",
    "    print(\"out = \" + str(out[0][1][1][0]))\n",
    "    \n",
    "    test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28f1f2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape, classes):\n",
    "    \"\"\"\n",
    "    功能：\n",
    "    实现resnet50残差网络\n",
    "    参数:\n",
    "    input_shape:输入数据的维度(n_H,n_W,n_C)\n",
    "    classes:分类种类\n",
    "    返回：\n",
    "    net:残差网络模型\n",
    "    \"\"\"\n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    #填充\n",
    "    X = ZeroPadding2D((3,3))(X_input)\n",
    "    \n",
    "    #stage 1\n",
    "    X = Conv2D(filters = 64, \n",
    "               kernel_size=(7,7),\n",
    "               strides=(2,2),\n",
    "               name=\"conv1\",\n",
    "               kernel_initializer=glorot_uniform(seed=0)\n",
    "              )(X)\n",
    "    X = BatchNormalization(axis=3, name=\"bn_conv1\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    X = MaxPooling2D(pool_size=(3,3), strides=(2,2))(X)\n",
    "\n",
    "    #stage 2\n",
    "    X = convolutional_block(X, f=3, filters=[64,64,256], stage=2, block=\"a\", s=1)\n",
    "    X = identity_block(X, f=3, filters=[64,64,256], stage=2, block=\"b\")\n",
    "    X = identity_block(X, f=3, filters=[64,64,256], stage=2, block=\"c\")\n",
    "    \n",
    "    #stage3\n",
    "    X = convolutional_block(X, f=3, filters=[128,128,512], stage=3, block=\"a\", s=2)\n",
    "    X = identity_block(X, f=3, filters=[128,128,512], stage=3, block=\"b\")\n",
    "    X = identity_block(X, f=3, filters=[128,128,512], stage=3, block=\"c\")\n",
    "    X = identity_block(X, f=3, filters=[128,128,512], stage=3, block=\"d\")\n",
    "    \n",
    "    #stage4\n",
    "    X = convolutional_block(X, f=3, filters=[256,256,1024], stage=4, block=\"a\", s=2)\n",
    "    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block=\"b\")\n",
    "    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block=\"c\")\n",
    "    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block=\"d\")\n",
    "    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block=\"e\")\n",
    "    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block=\"f\")\n",
    "    \n",
    "    #stage5\n",
    "    X = convolutional_block(X, f=3, filters=[512,512,2048], stage=5, block=\"a\", s=2)\n",
    "    X = identity_block(X, f=3, filters=[512,512,2048], stage=5, block=\"b\")\n",
    "    X = identity_block(X, f=3, filters=[512,512,2048], stage=5, block=\"c\")\n",
    "    \n",
    "    #均匀池化\n",
    "    X = AveragePooling2D(pool_size=(2,2), padding=\"same\", name=\"avg_pool\")(X) \n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, \n",
    "              activation=\"softmax\", \n",
    "              name=\"fc\"+str(classes),\n",
    "              kernel_initializer=glorot_uniform(seed=0)\n",
    "             )(X)\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X, name = \"ResNet\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = ResNet50(input_shape=(64,64,3), classes=6)\n",
    "model.compile(\"adam\", \"binary_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b03d13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 1080\n",
      "number of test examples = 120\n",
      "X_train shape: (1080, 64, 64, 3)\n",
      "Y_train shape: (1080, 6)\n",
      "X_test shape: (120, 64, 64, 3)\n",
      "Y_test shape: (120, 6)\n",
      "Train on 1080 samples\n",
      "Epoch 1/2\n",
      "1080/1080 [==============================] - 28s 26ms/sample - loss: 0.5475 - acc: 0.8340\n",
      "Epoch 2/2\n",
      "1080/1080 [==============================] - 9s 8ms/sample - loss: 0.1969 - acc: 0.9225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YinJianxiang\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "误差值 = 0.609339439868927\n",
      "准确率 = 0.72222227\n"
     ]
    }
   ],
   "source": [
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = resnets_utils.load_dataset()\n",
    "\n",
    "X_train = X_train_orig / 255\n",
    "X_test = X_test_orig / 255\n",
    "\n",
    "Y_train = resnets_utils.convert_to_one_hot(Y_train_orig,6).T\n",
    "Y_test = resnets_utils.convert_to_one_hot(Y_test_orig,6).T\n",
    "\n",
    "print(\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print(\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print(\"X_train shape: \" + str(X_train.shape))\n",
    "print(\"Y_train shape: \" + str(Y_train.shape))\n",
    "print(\"X_test shape: \" + str(X_test.shape))\n",
    "print(\"Y_test shape: \" + str(Y_test.shape))\n",
    "\n",
    "model.fit(X_train,Y_train,epochs=2,batch_size=32)\n",
    "preds = model.evaluate(X_test,Y_test)\n",
    "\n",
    "print(\"误差值 = \" + str(preds[0]))\n",
    "print(\"准确率 = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33aeb7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
