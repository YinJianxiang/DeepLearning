{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39beb571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 600\n",
      "number of test examples = 150\n",
      "X_train shape: (600, 64, 64, 3)\n",
      "Y_train shape: (600, 1)\n",
      "X_test shape: (150, 64, 64, 3)\n",
      "Y_test shape: (150, 1)\n",
      "Epoch 1/40\n",
      "12/12 [==============================] - 87s 66ms/step - loss: 2.4965 - accuracy: 0.5367\n",
      "Epoch 2/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.4878 - accuracy: 0.7900\n",
      "Epoch 3/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.2635 - accuracy: 0.8850\n",
      "Epoch 4/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.1638 - accuracy: 0.9367\n",
      "Epoch 5/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.1480 - accuracy: 0.9467\n",
      "Epoch 6/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.1122 - accuracy: 0.9650\n",
      "Epoch 7/40\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.0970 - accuracy: 0.9650\n",
      "Epoch 8/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0872 - accuracy: 0.9783\n",
      "Epoch 9/40\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.0757 - accuracy: 0.9833\n",
      "Epoch 10/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0626 - accuracy: 0.9817\n",
      "Epoch 11/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0695 - accuracy: 0.9833\n",
      "Epoch 12/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0749 - accuracy: 0.9750\n",
      "Epoch 13/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0624 - accuracy: 0.9817\n",
      "Epoch 14/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0465 - accuracy: 0.9883\n",
      "Epoch 15/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0558 - accuracy: 0.9817\n",
      "Epoch 16/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0463 - accuracy: 0.9867\n",
      "Epoch 17/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0423 - accuracy: 0.9900\n",
      "Epoch 18/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0353 - accuracy: 0.9933\n",
      "Epoch 19/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0440 - accuracy: 0.9900\n",
      "Epoch 20/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0295 - accuracy: 0.9933\n",
      "Epoch 21/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0343 - accuracy: 0.9933\n",
      "Epoch 22/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0307 - accuracy: 0.9883\n",
      "Epoch 23/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0315 - accuracy: 0.9933\n",
      "Epoch 24/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0227 - accuracy: 0.9983\n",
      "Epoch 25/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0298 - accuracy: 0.9933\n",
      "Epoch 26/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0239 - accuracy: 0.9950\n",
      "Epoch 27/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0242 - accuracy: 0.9917\n",
      "Epoch 28/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0365 - accuracy: 0.9883\n",
      "Epoch 29/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0213 - accuracy: 0.9917\n",
      "Epoch 30/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0310 - accuracy: 0.9933\n",
      "Epoch 31/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0223 - accuracy: 0.9933\n",
      "Epoch 32/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0359 - accuracy: 0.9900\n",
      "Epoch 33/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0157 - accuracy: 0.9967\n",
      "Epoch 34/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0193 - accuracy: 0.9967\n",
      "Epoch 35/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 36/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0142 - accuracy: 0.9967\n",
      "Epoch 37/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0117 - accuracy: 0.9983\n",
      "Epoch 38/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0176 - accuracy: 0.9967\n",
      "Epoch 39/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0154 - accuracy: 0.9967\n",
      "Epoch 40/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0121 - accuracy: 1.0000\n",
      "5/5 [==============================] - 1s 20ms/step - loss: 0.2426 - accuracy: 0.9200\n",
      "误差值 = 0.24262061715126038\n",
      "准确度 = 0.9200000166893005\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPool2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import kt_utils \n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = kt_utils.load_dataset()\n",
    "\n",
    "X_train = X_train_orig / 255\n",
    "X_test = X_test_orig / 255\n",
    "\n",
    "Y_train = Y_train_orig.T\n",
    "Y_test = Y_test_orig.T\n",
    "\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))\n",
    "\n",
    "def Happy_model(input_shape):\n",
    "    #定义一个placeholder，维度input_shape\n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    #对X使用 CONV -> BN -> RELU 块\n",
    "    X = Conv2D(32, (7, 7), strides = (1, 1), name='conv0')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    #最大池化层\n",
    "    X = MaxPooling2D((2, 2), name = 'max_pool')(X)\n",
    "    \n",
    "    #降维\n",
    "    X = Flatten()(X)\n",
    "    #全连接层FC\n",
    "    X = Dense(1, activation='sigmoid')(X)\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X, name = 'HappyFaceModel')\n",
    "    \n",
    "    return model\n",
    "\n",
    "happy_model = Happy_model(X_train.shape[1:])\n",
    "happy_model.compile(\"adam\", \"binary_crossentropy\", metrics=['accuracy'])\n",
    "happy_model.fit(X_train, Y_train, epochs=40, batch_size=50)\n",
    "\n",
    "preds = happy_model.evaluate(X_test, Y_test, batch_size=32, verbose=1, sample_weight=None)\n",
    "print (\"误差值 = \" + str(preds[0]))\n",
    "print (\"准确度 = \" + str(preds[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc36f8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out = [0.        0.        1.3454674 2.0318177 0.        1.3246754]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b1b5509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out = [0.        0.        0.        0.8929657 0.        0.1988273]\n"
     ]
    }
   ],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
    "    \"\"\"\n",
    "    功能：\n",
    "    实现跳跃三层的恒等快\n",
    "    参数：\n",
    "    X:输入数据,维度(m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f:第二部分卷积层的维度\n",
    "    filters:每部分卷积层的过滤器个数\n",
    "    stage:命名参数，层数\n",
    "    block:命名参数，层的名字\n",
    "    s:第一部分、第三部分、X_shortcut的stride\n",
    "    返回值：\n",
    "    X_out:恒等快输出，维度(n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    conv_name_base = \"res\" + str(stage) + block + \"_branch\"\n",
    "    bn_name_base = \"bn\" + str(stage) + block + \"_branch\"\n",
    "    \n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    X_shortcut = X\n",
    "    \n",
    "    #第一部分\n",
    "    X = Conv2D(filters = F1, \n",
    "               kernel_size=(1,1),\n",
    "               strides=(s,s),\n",
    "               padding=\"valid\",\n",
    "               name=conv_name_base+\"2a\",\n",
    "               kernel_initializer=glorot_uniform(seed=0)\n",
    "              )(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base+\"2a\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    #第二部分\n",
    "    X = Conv2D(filters = F2, \n",
    "               kernel_size=(f,f),\n",
    "               strides=(1,1),\n",
    "               padding=\"same\",\n",
    "               name=conv_name_base+\"2b\",\n",
    "               kernel_initializer=glorot_uniform(seed=0)\n",
    "              )(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base+\"2b\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    #第三部分\n",
    "    X = Conv2D(filters = F3, \n",
    "               kernel_size=(1,1),\n",
    "               strides=(1,1),\n",
    "               padding=\"valid\",\n",
    "               name=conv_name_base+\"2c\",\n",
    "               kernel_initializer=glorot_uniform(seed=0)\n",
    "              )(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base+\"2c\")(X)\n",
    "    \n",
    "    #shortcut\n",
    "    X_shortcut = Conv2D(filters = F3, \n",
    "               kernel_size=(1,1),\n",
    "               strides=(s,s),\n",
    "               padding=\"valid\",\n",
    "               name=conv_name_base+\"1\",\n",
    "               kernel_initializer=glorot_uniform(seed=0)\n",
    "              )(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base+\"1\")(X_shortcut)\n",
    "    \n",
    "    #求和\n",
    "    X = Add()([X, X_shortcut])\n",
    "    #激活\n",
    "    X_output = Activation(\"relu\")(X)\n",
    "    \n",
    "    return X_output    \n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as test:\n",
    "    np.random.seed(1)\n",
    "    A_prev = tf.placeholder(\"float\",[3,4,4,6])\n",
    "    X = np.random.randn(3,4,4,6)\n",
    "    \n",
    "    A = convolutional_block(A_prev,f=2,filters=[2,4,6],stage=1,block=\"a\")\n",
    "    test.run(tf.global_variables_initializer())\n",
    "    \n",
    "    out = test.run([A],feed_dict={A_prev:X,K.learning_phase():0})\n",
    "    print(\"out = \" + str(out[0][1][1][0]))\n",
    "    \n",
    "    test.close()\n",
    "\n",
    "def ResNet50(input_shape, classes):\n",
    "    \"\"\"\n",
    "    功能：\n",
    "    实现resnet50残差网络\n",
    "    参数:\n",
    "    input_shape:输入数据的维度(n_H,n_W,n_C)\n",
    "    classes:分类种类\n",
    "    返回：\n",
    "    net:残差网络模型\n",
    "    \"\"\"\n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    #填充\n",
    "    X = ZeroPadding2D((3,3))(X_input)\n",
    "    \n",
    "    #stage 1\n",
    "    X = Conv2D(filters = 64, \n",
    "               kernel_size=(7,7),\n",
    "               strides=(2,2),\n",
    "               name=\"conv1\",\n",
    "               kernel_initializer=glorot_uniform(seed=0)\n",
    "              )(X)\n",
    "    X = BatchNormalization(axis=3, name=\"bn_conv1\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    X = MaxPooling2D(pool_size=(3,3), strides=(2,2))(X)\n",
    "    \n",
    "    #stage 2\n",
    "    X = convolutional_block(X, f=3, filters=[64,64,256], stage=2, block=\"a\", s=1)\n",
    "    X = identity_block(X, f=3, filters=[64,64,256], stage=2, block=\"b\")\n",
    "    X = identity_block(X, f=3, filters=[64,64,256], stage=2, block=\"c\")\n",
    "    \n",
    "    #stage3\n",
    "    X = convolutional_block(X, f=3, filters=[128,128,512], stage=3, block=\"a\", s=2)\n",
    "    X = identity_block(X, f=3, filters=[128,128,512], stage=3, block=\"b\")\n",
    "    X = identity_block(X, f=3, filters=[128,128,512], stage=3, block=\"c\")\n",
    "    X = identity_block(X, f=3, filters=[128,128,512], stage=3, block=\"d\")\n",
    "    \n",
    "    #stage4\n",
    "    X = convolutional_block(X, f=3, filters=[256,256,1024], stage=4, block=\"a\", s=2)\n",
    "    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block=\"b\")\n",
    "    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block=\"c\")\n",
    "    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block=\"d\")\n",
    "    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block=\"e\")\n",
    "    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block=\"f\")\n",
    "    \n",
    "    #stage5\n",
    "    X = convolutional_block(X, f=3, filters=[512,512,2048], stage=5, block=\"a\", s=2)\n",
    "    X = identity_block(X, f=3, filters=[512,512,2048], stage=5, block=\"b\")\n",
    "    X = identity_block(X, f=3, filters=[512,512,2048], stage=5, block=\"c\")\n",
    "    \n",
    "    #均匀池化\n",
    "    X = AveragePooling2D(pool_size=(2,2), padding=\"same\", name=\"avg_pool\")(X) \n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, \n",
    "              activation=\"softmax\", \n",
    "              name=\"fc\"+str(classes),\n",
    "              kernel_initializer=glorot_uniform(seed=0)\n",
    "             )(X)\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X, name = \"ResNet\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = ResNet50(input_shape=(64,64,3), classes=6)\n",
    "model.compile(\"adam\", \"binary_crossentropy\", metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9329a39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
