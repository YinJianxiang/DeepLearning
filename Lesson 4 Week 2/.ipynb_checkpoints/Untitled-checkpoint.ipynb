{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39beb571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 600\n",
      "number of test examples = 150\n",
      "X_train shape: (600, 64, 64, 3)\n",
      "Y_train shape: (600, 1)\n",
      "X_test shape: (150, 64, 64, 3)\n",
      "Y_test shape: (150, 1)\n",
      "Epoch 1/40\n",
      "12/12 [==============================] - 87s 66ms/step - loss: 2.4965 - accuracy: 0.5367\n",
      "Epoch 2/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.4878 - accuracy: 0.7900\n",
      "Epoch 3/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.2635 - accuracy: 0.8850\n",
      "Epoch 4/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.1638 - accuracy: 0.9367\n",
      "Epoch 5/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.1480 - accuracy: 0.9467\n",
      "Epoch 6/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.1122 - accuracy: 0.9650\n",
      "Epoch 7/40\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.0970 - accuracy: 0.9650\n",
      "Epoch 8/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0872 - accuracy: 0.9783\n",
      "Epoch 9/40\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.0757 - accuracy: 0.9833\n",
      "Epoch 10/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0626 - accuracy: 0.9817\n",
      "Epoch 11/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0695 - accuracy: 0.9833\n",
      "Epoch 12/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0749 - accuracy: 0.9750\n",
      "Epoch 13/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0624 - accuracy: 0.9817\n",
      "Epoch 14/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0465 - accuracy: 0.9883\n",
      "Epoch 15/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0558 - accuracy: 0.9817\n",
      "Epoch 16/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0463 - accuracy: 0.9867\n",
      "Epoch 17/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0423 - accuracy: 0.9900\n",
      "Epoch 18/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0353 - accuracy: 0.9933\n",
      "Epoch 19/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0440 - accuracy: 0.9900\n",
      "Epoch 20/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0295 - accuracy: 0.9933\n",
      "Epoch 21/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0343 - accuracy: 0.9933\n",
      "Epoch 22/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0307 - accuracy: 0.9883\n",
      "Epoch 23/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0315 - accuracy: 0.9933\n",
      "Epoch 24/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0227 - accuracy: 0.9983\n",
      "Epoch 25/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0298 - accuracy: 0.9933\n",
      "Epoch 26/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0239 - accuracy: 0.9950\n",
      "Epoch 27/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0242 - accuracy: 0.9917\n",
      "Epoch 28/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0365 - accuracy: 0.9883\n",
      "Epoch 29/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0213 - accuracy: 0.9917\n",
      "Epoch 30/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0310 - accuracy: 0.9933\n",
      "Epoch 31/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0223 - accuracy: 0.9933\n",
      "Epoch 32/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0359 - accuracy: 0.9900\n",
      "Epoch 33/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0157 - accuracy: 0.9967\n",
      "Epoch 34/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0193 - accuracy: 0.9967\n",
      "Epoch 35/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 36/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0142 - accuracy: 0.9967\n",
      "Epoch 37/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0117 - accuracy: 0.9983\n",
      "Epoch 38/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0176 - accuracy: 0.9967\n",
      "Epoch 39/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0154 - accuracy: 0.9967\n",
      "Epoch 40/40\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0121 - accuracy: 1.0000\n",
      "5/5 [==============================] - 1s 20ms/step - loss: 0.2426 - accuracy: 0.9200\n",
      "误差值 = 0.24262061715126038\n",
      "准确度 = 0.9200000166893005\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPool2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import kt_utils \n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = kt_utils.load_dataset()\n",
    "\n",
    "X_train = X_train_orig / 255\n",
    "X_test = X_test_orig / 255\n",
    "\n",
    "Y_train = Y_train_orig.T\n",
    "Y_test = Y_test_orig.T\n",
    "\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))\n",
    "\n",
    "def Happy_model(input_shape):\n",
    "    #定义一个placeholder，维度input_shape\n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    #对X使用 CONV -> BN -> RELU 块\n",
    "    X = Conv2D(32, (7, 7), strides = (1, 1), name='conv0')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    #最大池化层\n",
    "    X = MaxPooling2D((2, 2), name = 'max_pool')(X)\n",
    "    \n",
    "    #降维\n",
    "    X = Flatten()(X)\n",
    "    #全连接层FC\n",
    "    X = Dense(1, activation='sigmoid')(X)\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X, name = 'HappyFaceModel')\n",
    "    \n",
    "    return model\n",
    "\n",
    "happy_model = Happy_model(X_train.shape[1:])\n",
    "happy_model.compile(\"adam\", \"binary_crossentropy\", metrics=['accuracy'])\n",
    "happy_model.fit(X_train, Y_train, epochs=40, batch_size=50)\n",
    "\n",
    "preds = happy_model.evaluate(X_test, Y_test, batch_size=32, verbose=1, sample_weight=None)\n",
    "print (\"误差值 = \" + str(preds[0]))\n",
    "print (\"准确度 = \" + str(preds[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc36f8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out = [0.        0.        1.3454674 2.0318177 0.        1.3246754]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)\n",
    "\n",
    "import resnets_utils \n",
    "\n",
    "def identity_block(X, f, filters, stage, block):\n",
    "    \"\"\"\n",
    "    功能：\n",
    "    实现恒等块\n",
    "    参数：\n",
    "    X:输入数据,维度(m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f:第二部分卷积层的维度\n",
    "    filters:每部分卷积层的过滤器个数\n",
    "    stage:命名参数，层数\n",
    "    block:命名参数，层的名字\n",
    "    返回值：\n",
    "    X_out:恒等快输出，维度(n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "\n",
    "    conv_name_base = \"res\" + str(stage) + block + \"_branch\"\n",
    "    bn_name_base   = \"bn\"  + str(stage) + block + \"_branch\"\n",
    "    \n",
    "\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    X_shortcut = X\n",
    "    \n",
    "    #第一部分\n",
    "    X = Conv2D(filters=F1, \n",
    "               kernel_size=(1,1), \n",
    "               strides=(1,1),\n",
    "               padding=\"valid\",\n",
    "               name=conv_name_base+\"2a\", \n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3,name=bn_name_base+\"2a\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    #第二部分\n",
    "    X = Conv2D(filters=F2, kernel_size=(f,f),strides=(1,1), padding=\"same\",\n",
    "               name=conv_name_base+\"2b\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3,name=bn_name_base+\"2b\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    \n",
    "    #第三部分\n",
    "    X = Conv2D(filters=F3,\n",
    "               kernel_size=(1,1), \n",
    "               strides=(1,1),\n",
    "               padding=\"valid\",\n",
    "               name=conv_name_base+\"2c\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3,name=bn_name_base+\"2c\")(X)\n",
    "\n",
    "    X = Add()([X,X_shortcut])\n",
    "    X_output = Activation(\"relu\")(X)\n",
    "\n",
    "    return X_output\n",
    "\n",
    "\n",
    "#test 恒等快\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as test:\n",
    "    np.random.seed(1)\n",
    "    A_prev = tf.placeholder(\"float\",[3,4,4,6])\n",
    "    X = np.random.randn(3,4,4,6)\n",
    "    A = identity_block(A_prev,f=2,filters=[2,4,6],stage=1,block=\"a\")\n",
    "    \n",
    "    test.run(tf.global_variables_initializer())\n",
    "    out = test.run([A],feed_dict={A_prev:X,K.learning_phase():0})\n",
    "    print(\"out = \" + str(out[0][1][1][0]))\n",
    "    \n",
    "    test.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b1b5509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out = [0.        0.        0.        0.8000044 0.        0.       ]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Operands could not be broadcast together with shapes (4, 4, 512) (8, 8, 512)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-800b755abbde>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mResNet50\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"adam\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"binary_crossentropy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-800b755abbde>\u001b[0m in \u001b[0;36mResNet50\u001b[1;34m(input_shape, classes)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[1;31m#stage3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvolutional_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"a\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0midentity_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"b\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0midentity_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-800b755abbde>\u001b[0m in \u001b[0;36mconvolutional_block\u001b[1;34m(X, f, filters, stage, block, s)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;31m#求和\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_shortcut\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m     \u001b[1;31m#激活\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[0mX_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mActivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"relu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer_v1.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    743\u001b[0m           \u001b[1;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    744\u001b[0m           \u001b[1;31m# overridden).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 745\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    746\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer_v1.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2066\u001b[0m         \u001b[1;31m# operations.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2067\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2068\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2069\u001b[0m       \u001b[1;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2070\u001b[0m       \u001b[1;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(instance, input_shape)\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_shapes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_tuples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m     \u001b[0moutput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m     \u001b[1;31m# Return shapes from `fn` as TensorShapes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\layers\\merge.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    105\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m       \u001b[0moutput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_elemwise_op_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m     \u001b[1;31m# If the inputs have different ranks, we have to reshape them\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;31m# to make them broadcastable.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\layers\\merge.py\u001b[0m in \u001b[0;36m_compute_elemwise_op_output_shape\u001b[1;34m(self, shape1, shape2)\u001b[0m\n\u001b[0;32m     76\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m           raise ValueError(\n\u001b[0m\u001b[0;32m     79\u001b[0m               \u001b[1;34m'Operands could not be broadcast '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m               'together with shapes ' + str(shape1) + ' ' + str(shape2))\n",
      "\u001b[1;31mValueError\u001b[0m: Operands could not be broadcast together with shapes (4, 4, 512) (8, 8, 512)"
     ]
    }
   ],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
    "    \"\"\"\n",
    "    功能：\n",
    "    实现跳跃三层的恒等快\n",
    "    参数：\n",
    "    X:输入数据,维度(m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f:第二部分卷积层的维度\n",
    "    filters:每部分卷积层的过滤器个数\n",
    "    stage:命名参数，层数\n",
    "    block:命名参数，层的名字\n",
    "    s:第一部分、第三部分、X_shortcut的stride\n",
    "    返回值：\n",
    "    X_out:恒等快输出，维度(n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    conv_name_base = \"res\" + str(stage) + block + \"_branch\"\n",
    "    bn_name_base = \"bn\" + str(stage) + block + \"_branch\"\n",
    "    \n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    X_shortcut = X\n",
    "    \n",
    "    #第一部分\n",
    "    X = Conv2D(filters = F1, \n",
    "               kernel_size=(1,1),\n",
    "               strides=(s,s),\n",
    "               padding=\"valid\",\n",
    "               name=conv_name_base+\"2a\",\n",
    "               kernel_initializer=glorot_uniform(seed=0)\n",
    "              )(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base+\"2a\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    #第二部分\n",
    "    X = Conv2D(filters = F2, \n",
    "               kernel_size=(f,f),\n",
    "               strides=(1,1),\n",
    "               padding=\"same\",\n",
    "               name=conv_name_base+\"2b\",\n",
    "               kernel_initializer=glorot_uniform(seed=0)\n",
    "              )(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base+\"2b\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    #第三部分\n",
    "    X = Conv2D(filters = F3, \n",
    "               kernel_size=(1,1),\n",
    "               strides=(s,s),\n",
    "               padding=\"valid\",\n",
    "               name=conv_name_base+\"2c\",\n",
    "               kernel_initializer=glorot_uniform(seed=0)\n",
    "              )(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base+\"2c\")(X)\n",
    "    \n",
    "    #shortcut\n",
    "    X_shortcut = Conv2D(filters = F3, \n",
    "               kernel_size=(1,1),\n",
    "               strides=(s,s),\n",
    "               padding=\"valid\",\n",
    "               name=conv_name_base+\"1\",\n",
    "               kernel_initializer=glorot_uniform(seed=0)\n",
    "              )(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base+\"1\")(X_shortcut)\n",
    "    \n",
    "    #求和\n",
    "    X = Add()([X, X_shortcut])\n",
    "    #激活\n",
    "    X_output = Activation(\"relu\")(X)\n",
    "    \n",
    "    return X_output    \n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as test:\n",
    "    np.random.seed(1)\n",
    "    A_prev = tf.placeholder(\"float\",[3,4,4,6])\n",
    "    X = np.random.randn(3,4,4,6)\n",
    "    \n",
    "    A = convolutional_block(A_prev,f=2,filters=[2,4,6],stage=1,block=\"a\")\n",
    "    test.run(tf.global_variables_initializer())\n",
    "    \n",
    "    out = test.run([A],feed_dict={A_prev:X,K.learning_phase():0})\n",
    "    print(\"out = \" + str(out[0][1][1][0]))\n",
    "    \n",
    "    test.close()\n",
    "\n",
    "def ResNet50(input_shape, classes):\n",
    "    \"\"\"\n",
    "    功能：\n",
    "    实现resnet50残差网络\n",
    "    参数:\n",
    "    input_shape:输入数据的维度(n_H,n_W,n_C)\n",
    "    classes:分类种类\n",
    "    返回：\n",
    "    net:残差网络模型\n",
    "    \"\"\"\n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    #填充\n",
    "    X = ZeroPadding2D((3,3))(X_input)\n",
    "    \n",
    "    #stage 1\n",
    "    X = Conv2D(filters = 64, \n",
    "               kernel_size=(7,7),\n",
    "               strides=(2,2),\n",
    "               name=\"conv1\",\n",
    "               kernel_initializer=glorot_uniform(seed=0)\n",
    "              )(X)\n",
    "    X = BatchNormalization(axis=3, name=\"bn_conv1\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    X = MaxPooling2D(pool_size=(3,3), strides=(2,2))(X)\n",
    "    \n",
    "    #stage 2\n",
    "    X = convolutional_block(X, f=3, filters=[64,64,256], stage=2, block=\"a\", s=1)\n",
    "    X = identity_block(X, f=3, filters=[64,64,256], stage=2, block=\"b\")\n",
    "    X = identity_block(X, f=3, filters=[64,64,256], stage=2, block=\"c\")\n",
    "    \n",
    "    #stage3\n",
    "    X = convolutional_block(X, f=3, filters=[128,128,512], stage=3, block=\"a\", s=2)\n",
    "    X = identity_block(X, f=3, filters=[128,128,512], stage=3, block=\"b\")\n",
    "    X = identity_block(X, f=3, filters=[128,128,512], stage=3, block=\"c\")\n",
    "    X = identity_block(X, f=3, filters=[128,128,512], stage=3, block=\"d\")\n",
    "    \n",
    "    #stage4\n",
    "    X = convolutional_block(X, f=3, filters=[256,256,1024], stage=4, block=\"a\", s=2)\n",
    "    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block=\"b\")\n",
    "    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block=\"c\")\n",
    "    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block=\"d\")\n",
    "    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block=\"e\")\n",
    "    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block=\"f\")\n",
    "    \n",
    "    #stage5\n",
    "    X = convolutional_block(X, f=3, filters=[512,512,2048], stage=5, block=\"a\", s=2)\n",
    "    X = identity_block(X, f=3, filters=[512,512,2048], stage=5, block=\"b\")\n",
    "    X = identity_block(X, f=3, filters=[512,512,2048], stage=5, block=\"c\")\n",
    "    \n",
    "    #均匀池化\n",
    "    X = AveragePooling2D(pool_size=(2,2), padding=\"same\", name=\"avg_pool\")(X) \n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, \n",
    "              activation=\"softmax\", \n",
    "              name=\"fc\"+str(classes),\n",
    "              kernel_initializer=glorot_uniform(seed=0)\n",
    "             )(X)\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X, name = \"ResNet\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = ResNet50(input_shape=(64,64,3), classes=6)\n",
    "model.compile(\"adam\", \"binary_crossentropy\", metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9329a39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
