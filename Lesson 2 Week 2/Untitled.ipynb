{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d44150b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------测试update_parameters_with_gd-------------\n",
      "W1 = [[ 1.63535156 -0.62320365 -0.53718766]\n",
      " [-1.07799357  0.85639907 -2.29470142]]\n",
      "b1 = [[ 1.74604067]\n",
      " [-0.75184921]]\n",
      "W2 = [[ 0.32171798 -0.25467393  1.46902454]\n",
      " [-2.05617317 -0.31554548 -0.3756023 ]\n",
      " [ 1.1404819  -1.09976462 -0.1612551 ]]\n",
      "b2 = [[-0.88020257]\n",
      " [ 0.02561572]\n",
      " [ 0.57539477]]\n",
      "-------------测试random_mini_batches-------------\n",
      "第1个mini_batch_X 的维度为： (12288, 64)\n",
      "第1个mini_batch_Y 的维度为： (1, 64)\n",
      "第2个mini_batch_X 的维度为： (12288, 64)\n",
      "第2个mini_batch_Y 的维度为： (1, 64)\n",
      "第3个mini_batch_X 的维度为： (12288, 20)\n",
      "第3个mini_batch_Y 的维度为： (1, 20)\n",
      "-------------测试initialize_velocity-------------\n",
      "v[\"dW1\"] = [[0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "v[\"db1\"] = [[0.]\n",
      " [0.]]\n",
      "v[\"dW2\"] = [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "v[\"db2\"] = [[0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "-------------测试update_parameters_with_momentun-------------\n",
      "W1 = [[ 1.62544598 -0.61290114 -0.52907334]\n",
      " [-1.07347112  0.86450677 -2.30085497]]\n",
      "b1 = [[ 1.74493465]\n",
      " [-0.76027113]]\n",
      "W2 = [[ 0.31930698 -0.24990073  1.4627996 ]\n",
      " [-2.05974396 -0.32173003 -0.38320915]\n",
      " [ 1.13444069 -1.0998786  -0.1713109 ]]\n",
      "b2 = [[-0.87809283]\n",
      " [ 0.04055394]\n",
      " [ 0.58207317]]\n",
      "v[\"dW1\"] = [[-0.11006192  0.11447237  0.09015907]\n",
      " [ 0.05024943  0.09008559 -0.06837279]]\n",
      "v[\"db1\"] = [[-0.01228902]\n",
      " [-0.09357694]]\n",
      "v[\"dW2\"] = [[-0.02678881  0.05303555 -0.06916608]\n",
      " [-0.03967535 -0.06871727 -0.08452056]\n",
      " [-0.06712461 -0.00126646 -0.11173103]]\n",
      "v[\"db2\"] = [[0.02344157]\n",
      " [0.16598022]\n",
      " [0.07420442]]\n",
      "-------------测试initialize_adam-------------\n",
      "v[\"dW1\"] = [[0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "v[\"db1\"] = [[0.]\n",
      " [0.]]\n",
      "v[\"dW2\"] = [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "v[\"db2\"] = [[0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "s[\"dW1\"] = [[0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "s[\"db1\"] = [[0.]\n",
      " [0.]]\n",
      "s[\"dW2\"] = [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "s[\"db2\"] = [[0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "-------------测试update_with_parameters_with_adam-------------\n",
      "W1 = [[ 1.63176996 -0.61918101 -0.53559635]\n",
      " [-1.08039322  0.85798303 -2.2941141 ]]\n",
      "b1 = [[ 1.75223636]\n",
      " [-0.7537823 ]]\n",
      "W2 = [[ 0.32646369 -0.25679497  1.46953253]\n",
      " [-2.05271611 -0.31499261 -0.37662976]\n",
      " [ 1.14119404 -1.09246713 -0.16500361]]\n",
      "b2 = [[-0.88528301]\n",
      " [ 0.03478915]\n",
      " [ 0.57539062]]\n",
      "v[\"dW1\"] = [[-0.11006192  0.11447237  0.09015907]\n",
      " [ 0.05024943  0.09008559 -0.06837279]]\n",
      "v[\"db1\"] = [[-0.01228902]\n",
      " [-0.09357694]]\n",
      "v[\"dW2\"] = [[-0.02678881  0.05303555 -0.06916608]\n",
      " [-0.03967535 -0.06871727 -0.08452056]\n",
      " [-0.06712461 -0.00126646 -0.11173103]]\n",
      "v[\"db2\"] = [[0.02344157]\n",
      " [0.16598022]\n",
      " [0.07420442]]\n",
      "s[\"dW1\"] = [[0.01211363 0.01310392 0.00812866]\n",
      " [0.00252501 0.00811541 0.00467484]]\n",
      "s[\"db1\"] = [[0.00015102]\n",
      " [0.00875664]]\n",
      "s[\"dW2\"] = [[7.17640232e-04 2.81276921e-03 4.78394595e-03]\n",
      " [1.57413361e-03 4.72206320e-03 7.14372576e-03]\n",
      " [4.50571368e-03 1.60392066e-06 1.24838242e-02]]\n",
      "s[\"db2\"] = [[0.00054951]\n",
      " [0.02754943]\n",
      " [0.0055063 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import math\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "\n",
    "import opt_utils\n",
    "import testCase\n",
    "\n",
    "%matplotlib inline \n",
    "plt.rcParams['figure.figsize'] = (7.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "def update_parameters_with_gd(parameters, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    功能：\n",
    "    使用梯度下降更新参数\n",
    "    \n",
    "    参数：\n",
    "    parameter:包含参数的字典\n",
    "    parameters['W' + str(l)] = Wl\n",
    "    parameters['b' + str(l)] = bl\n",
    "   \n",
    "   grads:包含梯度值的字典\n",
    "    grads['dW' + str(l)] = dWl\n",
    "    grads['db' + str(l)] = dbl\n",
    "    \n",
    "    learning_rate:学习率\n",
    "    返回值：\n",
    "    parameters:包含参数的字典\n",
    "    \"\"\"\n",
    "    L = len(parameters) // 2\n",
    "    \n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l + 1)] = parameters[\"W\" + str(l + 1)] - learning_rate * grads[\"dW\" + str(l + 1)]\n",
    "        parameters[\"b\" + str(l + 1)] = parameters[\"b\" + str(l + 1)] - learning_rate * grads[\"db\" + str(l + 1)]\n",
    "        \n",
    "    return parameters\n",
    "\n",
    "#测试update_parameters_with_gd\n",
    "print(\"-------------测试update_parameters_with_gd-------------\")\n",
    "parameters , grads , learning_rate = testCase.update_parameters_with_gd_test_case()\n",
    "parameters = update_parameters_with_gd(parameters,grads,learning_rate)\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))\n",
    "\n",
    "#mini-batch梯度下降\n",
    "#第一个mini-batch\n",
    "#first_mini_batch_X = shuffled_X[:, 0 : mini_batch_size]\n",
    "#第二个mini-batch\n",
    "#second_mini_batch_X = shuffled_X[:, mini_batch_size : 2 * mini_batch_size]\n",
    "\n",
    "def random_mini_batches(X, Y, mini_batch_size,seed = 0):\n",
    "    \"\"\"\n",
    "    功能：\n",
    "    从(X,Y)中创建一个随机的mini-batch列表\n",
    "    参数：\n",
    "    X:输入数据，维度(n_x,m)\n",
    "    Y:输入数据的标签，维度(1,m)\n",
    "    mini_batch_size:mini_batch的样本数量\n",
    "    返回值：\n",
    "    mini_batches:mini_batch序列\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    m = X.shape[1]\n",
    "    mini_batches = []\n",
    "\n",
    "    #打乱顺序并对应匹配\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[: ,permutation]   \n",
    "    shuffled_Y = Y[: ,permutation].reshape((1, m))\n",
    "    \n",
    "    #分割\n",
    "    num_complete_minibatches = math.floor(m / mini_batch_size)\n",
    "    #扫地除法\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[:,k * mini_batch_size:(k+1) * mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:,k * mini_batch_size:(k+1) * mini_batch_size]\n",
    "        \n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    #处理剩余的数据\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[:,mini_batch_size * num_complete_minibatches:]\n",
    "        mini_batch_Y = shuffled_Y[:,mini_batch_size * num_complete_minibatches:]\n",
    "        \n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "        \n",
    "    return mini_batches\n",
    "\n",
    "#测试random_mini_batches\n",
    "print(\"-------------测试random_mini_batches-------------\")\n",
    "X_assess,Y_assess,mini_batch_size = testCase.random_mini_batches_test_case()\n",
    "mini_batches = random_mini_batches(X_assess,Y_assess,mini_batch_size)\n",
    "\n",
    "print(\"第1个mini_batch_X 的维度为：\",mini_batches[0][0].shape)\n",
    "print(\"第1个mini_batch_Y 的维度为：\",mini_batches[0][1].shape)\n",
    "print(\"第2个mini_batch_X 的维度为：\",mini_batches[1][0].shape)\n",
    "print(\"第2个mini_batch_Y 的维度为：\",mini_batches[1][1].shape)\n",
    "print(\"第3个mini_batch_X 的维度为：\",mini_batches[2][0].shape)\n",
    "print(\"第3个mini_batch_Y 的维度为：\",mini_batches[2][1].shape)\n",
    "\n",
    "#包含动量的梯度下降\n",
    "#v_dW[l] = \\beta * v_dW[l] + (1 - \\beta)dW[l] \n",
    "#W[l] = W[l] - learning_rate * v_dw[l]\n",
    "\n",
    "#v_db[l] = \\beta * v_db[l] + (1 - \\beta)db[l] \n",
    "#b[l] = b[l] - learning_rate * v_db[l]\n",
    "\n",
    "\n",
    "def initialize_velocity(parameters):\n",
    "    \"\"\"\n",
    "    功能:\n",
    "    初始化速度v字典\n",
    "    keys:\"dW1\", \"db1\", ..., \"dWL\", \"dbL\"\n",
    "    values:对应的速度\n",
    "    参数:\n",
    "    parameters:包含参数的字典\n",
    "    返回值:\n",
    "    v:包含速度的字典\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    L = len(parameters) // 2\n",
    "    v = {}\n",
    "    \n",
    "    for l in range(L):\n",
    "        v[\"dW\" + str(l + 1)] = np.zeros_like(parameters[\"W\" + str(l + 1)])\n",
    "        v[\"db\" + str(l + 1)] = np.zeros_like(parameters[\"b\" + str(l + 1)])\n",
    "        \n",
    "    return v\n",
    "\n",
    "#测试initialize_velocity\n",
    "print(\"-------------测试initialize_velocity-------------\")\n",
    "parameters = testCase.initialize_velocity_test_case()\n",
    "v = initialize_velocity(parameters)\n",
    "\n",
    "print('v[\"dW1\"] = ' + str(v[\"dW1\"]))\n",
    "print('v[\"db1\"] = ' + str(v[\"db1\"]))\n",
    "print('v[\"dW2\"] = ' + str(v[\"dW2\"]))\n",
    "print('v[\"db2\"] = ' + str(v[\"db2\"]))\n",
    "\n",
    "\n",
    "def update_parameters_with_momentun(parameters,grads,v,beta,learning_rate):\n",
    "    \"\"\"\n",
    "    功能:\n",
    "    包含动量的梯度下降\n",
    "    参数:\n",
    "    parameter:包含参数的字典\n",
    "    grads:包含梯度的字典\n",
    "    v:包含速度的字典\n",
    "    beta:超参数，动量\n",
    "    learning_rate:学习率\n",
    "    返回值:\n",
    "    parameter:更新后的参数字典\n",
    "    v:更新后的速度字典\n",
    "    \"\"\"\n",
    "\n",
    "    L = len(parameters) // 2\n",
    "    \n",
    "    for l in range(L):\n",
    "        v[\"dW\" + str(l + 1)] = beta * v[\"dW\" + str(l + 1)] + (1 - beta) * grads[\"dW\" + str(l + 1)]\n",
    "        v[\"db\" + str(l + 1)] = beta * v[\"db\" + str(l + 1)] + (1 - beta) * grads[\"db\" + str(l + 1)]\n",
    "        \n",
    "        parameters[\"W\" + str(l + 1)] = parameters[\"W\" + str(l + 1)] - learning_rate * v[\"dW\" + str(l + 1)]\n",
    "        parameters[\"b\" + str(l + 1)] = parameters[\"b\" + str(l + 1)] - learning_rate * v[\"db\" + str(l + 1)]\n",
    "    \n",
    "    return parameters,v    \n",
    "\n",
    "#测试update_parameters_with_momentun\n",
    "print(\"-------------测试update_parameters_with_momentun-------------\")\n",
    "parameters,grads,v = testCase.update_parameters_with_momentum_test_case()\n",
    "update_parameters_with_momentun(parameters,grads,v,beta = 0.9,learning_rate = 0.01)\n",
    "\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))\n",
    "print('v[\"dW1\"] = ' + str(v[\"dW1\"]))\n",
    "print('v[\"db1\"] = ' + str(v[\"db1\"]))\n",
    "print('v[\"dW2\"] = ' + str(v[\"dW2\"]))\n",
    "print('v[\"db2\"] = ' + str(v[\"db2\"]))\n",
    "\n",
    "\n",
    "#adam算法\n",
    "\n",
    "def initialize_adam(parameters):\n",
    "    \"\"\"\n",
    "    功能:\n",
    "    初始化v和s\n",
    "    参数:\n",
    "    parameter:包含参数的字典\n",
    "    返回值:\n",
    "    v:包含梯度的指数加权平均值的字典\n",
    "    s:包含平方梯度的指数加权平均值的字典\n",
    "    \"\"\"\n",
    "    L = len(parameters) // 2\n",
    "    v = {}\n",
    "    s = {}\n",
    "    \n",
    "    for l in range(L):\n",
    "        v[\"dW\" + str(l + 1)] = np.zeros_like(parameters[\"W\" + str(l + 1)])\n",
    "        v[\"db\" + str(l + 1)] = np.zeros_like(parameters[\"b\" + str(l + 1)])\n",
    "\n",
    "        s[\"dW\" + str(l + 1)] = np.zeros_like(parameters[\"W\" + str(l + 1)])\n",
    "        s[\"db\" + str(l + 1)] = np.zeros_like(parameters[\"b\" + str(l + 1)])\n",
    "\n",
    "    return v,s\n",
    "\n",
    "#测试initialize_adam\n",
    "print(\"-------------测试initialize_adam-------------\")\n",
    "parameters = testCase.initialize_adam_test_case()\n",
    "v,s = initialize_adam(parameters)\n",
    "\n",
    "print('v[\"dW1\"] = ' + str(v[\"dW1\"])) \n",
    "print('v[\"db1\"] = ' + str(v[\"db1\"])) \n",
    "print('v[\"dW2\"] = ' + str(v[\"dW2\"])) \n",
    "print('v[\"db2\"] = ' + str(v[\"db2\"])) \n",
    "print('s[\"dW1\"] = ' + str(s[\"dW1\"])) \n",
    "print('s[\"db1\"] = ' + str(s[\"db1\"])) \n",
    "print('s[\"dW2\"] = ' + str(s[\"dW2\"])) \n",
    "print('s[\"db2\"] = ' + str(s[\"db2\"])) \n",
    "\n",
    "def update_parameters_with_adam(parameters, grads, v, s, t , learning_rate = 0.01, beta1 = 0.9, beta2 = 0.99, epsilon = 1e-8):\n",
    "    \"\"\"\n",
    "    功能:\n",
    "    使用Adam更新参数\n",
    "    参数:\n",
    "    parameter:包含参数的字典\n",
    "    grads:包含梯度的字典\n",
    "    v:包含梯度的指数加权平均值的字典\n",
    "    s:包含平方梯度的指数加权平均值的字典\n",
    "    t:当前的迭代次数\n",
    "    learing_rate:学习率\n",
    "    beta1:动量，超参数\n",
    "    beta2:RMSprop的一个参数，超参数\n",
    "    epsilon:防止分母为0的参数，一般为1^-8\n",
    "    返回值:\n",
    "    parameter:更新后的参数字典\n",
    "    v:更新后的包含梯度的指数加权平均值的字典\n",
    "    s:更新后的包含平方梯度的指数加权平均值的字典\n",
    "    \"\"\"\n",
    "    L = len(parameters) // 2\n",
    "    #偏差修正后的值\n",
    "    v_corrected = {}\n",
    "    s_corrected = {}\n",
    "\n",
    "    for l in range(L):\n",
    "        v[\"dW\" + str(l + 1)] = beta1 * v[\"dW\" + str(l + 1)] + (1 - beta1) * grads[\"dW\" + str(l + 1)]\n",
    "        v[\"db\" + str(l + 1)] = beta1 * v[\"db\" + str(l + 1)] + (1 - beta1) * grads[\"db\" + str(l + 1)]\n",
    "        \n",
    "        v_corrected[\"dW\" + str(l + 1)] = v[\"dW\" + str(l + 1)] / (1 - np.power(beta1, t))\n",
    "        v_corrected[\"db\" + str(l + 1)] = v[\"db\" + str(l + 1)] / (1 - np.power(beta1, t))\n",
    "        \n",
    "        s[\"dW\" + str(l + 1)] = beta2 * s[\"dW\" + str(l + 1)] + (1 - beta2) * np.square(grads[\"dW\" + str(l + 1)])\n",
    "        s[\"db\" + str(l + 1)] = beta2 * s[\"db\" + str(l + 1)] + (1 - beta2) * np.square(grads[\"db\" + str(l + 1)])\n",
    "        \n",
    "        s_corrected[\"dW\" + str(l + 1)] = s[\"dW\" + str(l + 1)] / (1 - np.power(beta2, t))\n",
    "        s_corrected[\"db\" + str(l + 1)] = s[\"db\" + str(l + 1)] / (1 - np.power(beta2, t))\n",
    "        \n",
    "        parameters[\"W\" + str(l + 1)] = parameters[\"W\" + str(l + 1)] - learning_rate * (v_corrected[\"dW\" + str(l + 1)] / (np.sqrt(s_corrected[\"dW\" + str(l + 1)] + epsilon)))\n",
    "        parameters[\"b\" + str(l + 1)] = parameters[\"b\" + str(l + 1)] - learning_rate * (v_corrected[\"db\" + str(l + 1)] / (np.sqrt(s_corrected[\"db\" + str(l + 1)] + epsilon)))\n",
    "    \n",
    "    \n",
    "    return parameters, v, s \n",
    "\n",
    "#测试update_with_parameters_with_adam\n",
    "print(\"-------------测试update_with_parameters_with_adam-------------\")\n",
    "parameters , grads , v , s = testCase.update_parameters_with_adam_test_case()\n",
    "update_parameters_with_adam(parameters,grads,v,s,t=2)\n",
    "\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))\n",
    "print('v[\"dW1\"] = ' + str(v[\"dW1\"])) \n",
    "print('v[\"db1\"] = ' + str(v[\"db1\"])) \n",
    "print('v[\"dW2\"] = ' + str(v[\"dW2\"])) \n",
    "print('v[\"db2\"] = ' + str(v[\"db2\"])) \n",
    "print('s[\"dW1\"] = ' + str(s[\"dW1\"])) \n",
    "print('s[\"db1\"] = ' + str(s[\"db1\"])) \n",
    "print('s[\"dW2\"] = ' + str(s[\"dW2\"])) \n",
    "print('s[\"db2\"] = ' + str(s[\"db2\"])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2abd699",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
